<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Languages, Systems, and Data Lab @ UCSC on Languages, Systems, and Data Lab @ UCSC</title>
    <link>http://lsd-ucsc.github.io/</link>
    <description>Recent content in Languages, Systems, and Data Lab @ UCSC on Languages, Systems, and Data Lab @ UCSC</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 21 Feb 2021 12:27:37 -0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Languages, Systems, and Data Seminar (Spring 2021)</title>
      <link>http://lsd-ucsc.github.io/lsd-seminar/2021sp/</link>
      <pubDate>Sun, 21 Feb 2021 12:27:37 -0800</pubDate>
      
      <guid>http://lsd-ucsc.github.io/lsd-seminar/2021sp/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: Fridays, noon - 1:15pm (PT) &lt;br /&gt;
&lt;strong&gt;Location&lt;/strong&gt;: The Internet &lt;br /&gt;
&lt;strong&gt;Organizers&lt;/strong&gt;: Lindsey Kuper and Tyler Sorensen &lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The Languages, Systems, and Data Seminar meets weekly to discuss interesting topics in the areas of programming languages, systems, databases, formal methods, security, software engineering, verification, architecture, and beyond.  Our goal is to encourage interactions and discussions between students, researchers, and faculty with interests in these areas.  The seminar is open to everyone interested.  Participating students should register for the 2-credit course CSE 280O.&lt;/p&gt;

&lt;p&gt;For spring 2021, this seminar is completely virtual and will feature a mix of internal and external speakers.&lt;/p&gt;

&lt;p&gt;Talks will be advertised on the &lt;a href=&#34;https://groups.google.com/g/ucsc-lsd-seminar-announce&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ucsc-lsd-seminar-announce&lt;/a&gt; (for anyone) and &lt;a href=&#34;https://groups.google.com/a/ucsc.edu/g/lsd-group/members&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;lsd-group&lt;/a&gt; (for UCSC-affiliated people) mailing lists.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Speaker&lt;/th&gt;
&lt;th&gt;Title&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#april-2&#34;&gt;April 2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Aldrin Montana&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#april-9&#34;&gt;April 9&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Michael Arntzenius&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#april-16&#34;&gt;April 16&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Achilles Bentopoulos&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#april-23&#34;&gt;April 23&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Konstantinos Kallas&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#april-30&#34;&gt;April 30&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Eric Atkinson&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#may-7&#34;&gt;May 7&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Vadim Zaliva&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#may-14&#34;&gt;May 14&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Benjamin Valpey&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#may-21&#34;&gt;May 21&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Zeeshan Lakhani&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#may-28&#34;&gt;May 28&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Philippa Cowderoy&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#june-4&#34;&gt;June 4&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Ranysha Ware&lt;/td&gt;
&lt;td&gt;TBD&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;../&#34;&gt;Archive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Languages, Systems, and Data Seminar (Winter 2021)</title>
      <link>http://lsd-ucsc.github.io/lsd-seminar/2021wi/</link>
      <pubDate>Sat, 02 Jan 2021 21:45:29 -0800</pubDate>
      
      <guid>http://lsd-ucsc.github.io/lsd-seminar/2021wi/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: Fridays, noon - 1:15pm (PT) &lt;br/&gt;
&lt;strong&gt;Location&lt;/strong&gt;: The Internet &lt;br/&gt;
&lt;strong&gt;Organizers&lt;/strong&gt;: Lindsey Kuper and Tyler Sorensen &lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The Languages, Systems, and Data Seminar meets weekly to discuss interesting topics in the areas of programming languages, systems, databases, formal methods, security, software engineering, verification, architecture, and beyond.  Our goal is to encourage interactions and discussions between students, researchers, and faculty with interests in these areas.  The seminar is open to everyone interested.  Participating students should register for the 2-credit course CSE 280O.&lt;/p&gt;

&lt;p&gt;For winter 2021, this seminar is completely virtual and will feature a mix of internal and external speakers.&lt;/p&gt;

&lt;p&gt;Talks will be advertised on the &lt;a href=&#34;https://groups.google.com/g/ucsc-lsd-seminar-announce&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ucsc-lsd-seminar-announce&lt;/a&gt; (for anyone) and &lt;a href=&#34;https://groups.google.com/a/ucsc.edu/g/lsd-group/members&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;lsd-group&lt;/a&gt; (for UCSC-affiliated people) mailing lists.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Speaker&lt;/th&gt;
&lt;th&gt;Title&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#jan-8&#34;&gt;Jan. 8&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;Introductions and social time&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#jan-15&#34;&gt;Jan. 15&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://very.science/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Kenny Foner&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Dialectic: Pragmatic, Efficient Session Types for Async Rust&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#jan-22&#34;&gt;Jan. 22&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.cs.princeton.edu/~nhossain/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Naorin Hossain&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;TransForm: Formally Specifying Transistency Models and Synthesizing Enhanced Litmus Tests&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#jan-29&#34;&gt;Jan. 29&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://aviral.io/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Aviral Goel&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;On the Design, Implementation, and Use of Laziness in R&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#feb-5&#34;&gt;Feb. 5&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.victoraying.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Victor Ying&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Parallelizing Sequential Code with Compiler-Hardware Co-Design&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#feb-12&#34;&gt;Feb. 12&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://koronkevi.ch/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Paulette Koronkevich&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The ANF Translation Preserves Dependent Types up to Extensional Equality&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#feb-19&#34;&gt;Feb. 19&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Kamala Ramasubramanian&lt;/td&gt;
&lt;td&gt;ACT now: Aggregate Comparison of Traces for Incident Localization&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#feb-26&#34;&gt;Feb. 26&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://prakashmurali.bitbucket.io/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Prakash Murali&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Closing the Gap between Quantum Algorithms and Hardware using Compilation and Architecture&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#march-5&#34;&gt;March 5&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.vinujoseph.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Vinu Joseph&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Programmable Neural Network Compression with Correctness Emphasis&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#march-12&#34;&gt;March 12&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Daniel Bittman&lt;/td&gt;
&lt;td&gt;Twizzler: Evolving Operating Systems for Non-volatile Memory&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;jan-8&#34;&gt;Jan. 8&lt;/h1&gt;

&lt;p&gt;Introductions and social time&lt;/p&gt;

&lt;h1 id=&#34;jan-15&#34;&gt;Jan. 15&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://very.science/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Kenny Foner&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Dialectic: Pragmatic, Efficient Session Types for Async Rust&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Session types have long promised the ability to enforce complex temporal invariants about message ordering in distributed systems, guaranteeing that a well-session-typed program always correctly follows a messaging protocol to its end. Despite their potential, these type systems have seen relatively little adoption in the mainstream. In part, this is due to their inherent reliance on linear typing, a feature not present and difficult to emulate in most popular languages. Recently, this has changed with the emergence of Rust, a systems programming language built atop a flexible &amp;ldquo;ownership type system&amp;rdquo; to track reference aliasing. Although Rust enforces in actuality a form of affine typing (weaker than the linear typing most formal session-typed calculi require) it&amp;rsquo;s enough to build a library for session types that statically enforces the slightly-weaker guarantee that a program correctly follows a messaging protocol so long as it is running, but may quit the session early. Of course, this is the best we can hope to get in the real world! Networks go down, computers crash, and hardware just plain breaks. For session types to be broadly adopted, they must survive contact with this real and unpredictable world—and equally, with the real and unpredictable people who want to use them in their programs.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve just released version 0.2 of &lt;a href=&#34;https://docs.rs/dialectic&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Dialectic&lt;/a&gt;: a library for pragmatic, succinct, efficient session types in Rust. Dialectic embraces Rust&amp;rsquo;s burgeoning ecosystem of high-performance async networking by being polymorphic over any backend transport used to convey messages between parties. Unlike many libraries for session types, Dialectic assumes that the other party might break protocol or disconnect at any time, and is designed to gracefully handle such failures without compromising type safety.  Dialectic is designed to be used for writing specifications and programs of every size from small to large, and provides what&amp;rsquo;s needed to write modular specifications and implementations of complex protocols—and not merely the regular session types expressible in most libraries, but all context-free session types.&lt;/p&gt;

&lt;p&gt;More than merely showing off this cool thing I&amp;rsquo;m working on, I want to talk about the design process that went into making it. Designing a programming paradigm—whether you want to call it an embedded domain-specific language or merely a library—is a multi-faceted puzzle spanning considerations from psychological familiarity to formal computability. My hope is that in walking through this case study in embedded language design, we can spark more thoughts about how we as PL researchers can play in this field together and design beautiful, useful tools.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Kenny Foner (kwf@very.science) is a senior software engineer at Bolt Labs working on privacy-preserving financial technology for everyone. They have a master&amp;rsquo;s degree in programming languages from the University of Pennsylvania, where they worked on a smorgasbord of fun things from laziness to random testing. When they&amp;rsquo;re not writing Rust, they&amp;rsquo;re usually somewhere in the forest.&lt;/p&gt;

&lt;h1 id=&#34;jan-22&#34;&gt;Jan. 22&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://www.cs.princeton.edu/~nhossain/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Naorin Hossain&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; TransForm: Formally Specifying Transistency Models and Synthesizing Enhanced Litmus Tests&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Memory consistency models (MCMs) have been formulated as a mechanism for expressing the legal ordering and visibility of shared memory accesses in hardware and software. They are fundamental for ensuring heterogeneous components of a system execute and interact as expected to prevent hardware-induced bugs in real-world programs. However, ISA-level MCMs are limited to defining the behavior of only user-facing assembly instructions and do not account for virtual memory implementations that may result in the execution of 1) hardware-level state updates and 2) system-level interactions. Both are capable of accessing memory and may affect program outcomes, thus making them software-visible. As a result, memory transistency models (MTMs) have been coined as a superset of MCMs to additionally capture and enforce virtual memory-aware ordering rules. However, no prior work enabled the formal specification or analysis of MTMs.&lt;/p&gt;

&lt;p&gt;TransForm fills this gap by introducing an axiomatic vocabulary for formally specifying MTMs that builds on the standard axiomatic vocabulary traditionally used for describing MCMs. It provides new constructs for modeling transistency-specific features such as hardware-level state updates and system-level interactions. Using this new axiomatic vocabulary, MTMs can be formally specified and used with TransForm’s synthesis engine to synthesize litmus tests enhanced with transistency features, called enhanced litmus tests. This talk will cover TransForm’s axiomatic vocabulary and synthesis engine, as well as a case study performed with TransForm to formally define an approximate MTM for Intel x86 processors.&lt;/p&gt;

&lt;h1 id=&#34;jan-29&#34;&gt;Jan. 29&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;http://aviral.io/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Aviral Goel&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; On the Design, Implementation, and Use of Laziness in R&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In this talk, I will present the design and implementation of call-by-need in R, and a data-driven study of how generations of programmers have put laziness to use in their code. In our study, we analyze 16,707 R packages and observe the creation of 270.9 B promises. Our data suggest that there is little supporting evidence to assert that programmers use laziness to avoid unnecessary computation or to operate over infinite data structures. For the most part R code appears to have been written without reliance on and in many cases even knowledge of, delayed argument evaluation. The only significant exception is a small number of packages which leverage call-by-need for meta-programming. I will discuss how we intend to leverage these insights to remove laziness from R and enable non-intrusive migration of code from lazy to eager evaluation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Aviral Goel is a Computer Science Ph.D. student at Northeastern University, advised by Professor Jan Vitek. He received his Bachelor&amp;rsquo;s degree in Electronics and Communication Engineering from Netaji Subhas Institute of Technology, India.&lt;/p&gt;

&lt;p&gt;He is interested in improving tools and techniques for data science applications. He is enabling R programmers to write faster and bug-free code by migrating the language from lazy-by-default to lazy-on-demand semantics.&lt;/p&gt;

&lt;p&gt;He is also involved in the development of a type system for R.&lt;/p&gt;

&lt;h1 id=&#34;feb-5&#34;&gt;Feb. 5&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://www.victoraying.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Victor Ying&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Parallelizing Sequential Code with Compiler-Hardware Co-Design&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Today, most code still runs on expensive, power-hungry processors that prioritize single-thread performance. Speculative parallelization is an enticing approach to accelerate computation while retaining the ease of sequential programming, by launching tasks in parallel before knowing if they are independent. Unfortunately, prior speculative parallelizing compilers and architectures achieved limited speedups due to high costs of recovering from misspeculation and hardware scalability bottlenecks.&lt;/p&gt;

&lt;p&gt;We present T4, a parallelizing compiler that executes sequential programs as trees of tiny timestamped tasks. T4 targets the recent Swarm architecture, which presents new opportunities and challenges for automatic parallelization. T4 introduces novel compiler techniques to expose parallelism aggressively across the entire program, breaking applications into tiny tasks of tens of instructions each. Task trees unfold their branches in parallel to enable high task-spawn throughput while exploiting selective aborts to recover from misspeculation cheaply. T4 exploits parallelism across function calls, loops, and loop nests; performs new transformations to reduce task spawn costs and avoid false sharing; and exploits data locality among fine-grain tasks. As a result, T4 scales several hard-to-parallelize SPEC CPU2006 benchmarks to tens of cores, where prior work attained little or no speedup.&lt;/p&gt;

&lt;p&gt;For more information, please visit &lt;a href=&#34;swarm.csail.mit.edu&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;swarm.csail.mit.edu&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Victor Ying is a 5th year PhD student at MIT, advised by Daniel Sanchez. He works on parallel architectures, compilers, and programming models. Victor&amp;rsquo;s recent work focuses on redesigning abstractions between hardware and software to make it as easy to exploit multicore parallelism as it is to write ordinary sequential programs. His prior work includes Boolean satisfiability solvers, scheduling machine learning workloads on hardware accelerators, and embedded and distributed systems.&lt;/p&gt;

&lt;h1 id=&#34;feb-12&#34;&gt;Feb. 12&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://koronkevi.ch/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Paulette Koronkevich&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; The ANF Translation Preserves Dependent Types up to Extensional Equality&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Many programmers use dependently-typed languages like Coq to
machine-verify high-assurance software. However, existing compilers for
these languages provide no guarantees after compiling, nor when linking
after compilation. Type-preserving compilers preserve guarantees encoded
in types, then use type checking to verify compiled code and ensure safe
linking with external code. Unfortunately, dependent type systems are
highly sensitive to syntactic changes, including compilation, so
preserving them through a compiler pass is difficult.&lt;/p&gt;

&lt;p&gt;In this talk, I will present some examples of why dependent typing is
difficult to preserve through simple syntactic changes. I will also
present our solution to preserving dependent types through the ANF
translation, a necessary transformation towards compiling a functional
language down to machine code. Our ANF translation preserves dependent
types, provided that the target type system has a way to encode these
syntactic semantics-preserving changes. We encode these by including
extensional equality in our target type system.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Paulette Koronkevich is a second year graduate student (finishing
MSc and starting PhD) at the University of British Columbia, working
with William J. Bowman. She has a undergraduate degree in computer
science from Indiana University. Her interests include compilers, cats,
and cooking.&lt;/p&gt;

&lt;h1 id=&#34;feb-19&#34;&gt;Feb. 19&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Kamala Ramasubramanian&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; ACT now: Aggregate Comparison of Traces for Incident Localization&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Incidents in production systems are common and downtime is expensive. Applying an appropriate mitigating action quickly, such as changing a specific firewall rule or routing around a broken network link, saves money. Identifying where to mitigate is time-consuming since a single failure can produce widespread effects. Knowing how different system events relate to each other is necessary to quickly identify where to mitigate. Our approach, Aggregate Comparison of Traces (ACT), localizes incidents by comparing sets of traces (which capture events and their relationships for individual requests) sampled from the most recent steady-state operation and during an incident. In our quantitative experiments, we conduct hundreds of simulations and show that ACT is able to identify exactly where to mitigate in all but a few cases.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Kamala Ramasubramanian is a PhD candidate at University of California, Santa Cruz advised by Peter Alvaro. She works on understanding, implementing and troubleshooting distributed systems by reasoning about observed system executions. She recently became interested in system verification and how it may overlap with her current work. She is a vegetarian foodie, likes to CrossFit and wants to try surfing.&lt;/p&gt;

&lt;h1 id=&#34;feb-26&#34;&gt;Feb. 26&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://prakashmurali.bitbucket.io/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Prakash Murali&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Closing the Gap between Quantum Algorithms and Hardware using Compilation and Architecture&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In recent years, quantum computing (QC) hardware has progressed considerably with small systems being prototyped by industry and academic vendors. However, there is a huge gap between the resource requirements of promising applications and the hardware that is buildable now; qubit counts and operational noise constraints of applications exceed hardware capabilities by 5-6 orders of magnitude. Our work seeks to enable practical QC by bridging this gap: from the top with novel compiler techniques and algorithmic optimizations to reduce application requirements and from the bottom via system architectures efficiently exploiting scarce QC resources.&lt;/p&gt;

&lt;p&gt;In this talk, we present two cross-cutting optimizations that narrow the applications-to-hardware resource gap. First, we present noise-adaptive compilation techniques that optimize applications for the spatio-temporal noise variations seen in real QC systems. Using real executions, we demonstrate average fidelity improvements of 3X using noise-adaptivity, compared to industry compiler tools. Second, on the architecture front, we study instruction set design issues considering application requirements and hardware gate calibration overheads. Current QC systems either use ISAs with a single two-qubit gate type or families of continuous gate sets. Using architectural simulations based on Google and Rigetti hardware, we show that QC instruction sets with 4-8 two-qubit gate types are best suited for expressing application requirements, while incurring tractable calibration overheads. In response to our work, several industry vendors have included noise-adaptivity and its extensions as part of their toolflows and adjusted device architecture to expose more native operations and hardware characterization data.&lt;/p&gt;

&lt;h1 id=&#34;march-5&#34;&gt;March 5&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Vinu Joseph&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Programmable Neural Network Compression with Correctness Emphasis&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Deep neural networks (DNNs) frequently contain far more weights, represented at higher precision, than are required for the specific task which they are trained to perform.
Consequently, they can often be compressed using techniques such as weight pruning and quantization that reduce both the model size and inference time without appreciable loss in accuracy.
However, finding the best compression strategy and corresponding target sparsity for a given DNN, hardware platform, and optimization objective currently requires expensive, frequently manual, trial-and-error experimentation.
In this talk, we introduce a programmable system for model compression called Condensa. Users programmatically compose simple operators, in Python, to build more complex and practically interesting compression strategies.
Given a strategy and user-provided objective (such as minimization of running time), Condensa uses a novel Bayesian optimization-based algorithm to automatically infer desirable sparsities.
Our experiments real-world DNNs demonstrate memory footprint and hardware runtime throughput improvements of 188x and 2.59x, respectively, using at most ten samples per search.
We have released a reference implementation of &lt;a href=&#34;https://github.com/NVlabs/condensa&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Condensa&lt;/a&gt;. Next, we will talk about our recent correctness extension where we preserve not just the overall accuracy but also metrics relating to model fairness and interpretability.
To achieve this, we augment the compression loss function with terms arising from the teacher-student learning paradigm and show how to automatically tune the associated parameters.
We demonstrate the effectiveness of our approach on multiple compression schemes and accuracy recovery algorithms using several different real-world network architectures.
We obtain a significant reduction of up to 4.1X in the number of mismatches between the compressed and reference models, while also achieving a significant reduction in class-wise disparate impact metrics compared to the reference models.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Vinu Joseph is a Ph.D. candidate in Computer Science at the School of Computing at the University of Utah, Salt Lake City, working on efficient deep learning computing, robustness, and security of deep learning algorithms, advised by Prof. Ganesh Gopalakrishnan.
He is one of the five recipients of the NVIDIA Graduate fellowship, the recipients were selected based on their academic achievements and area of research.
Prior to graduate studies, Vinu worked at ARM Inc. During his tenure at ARM, he was a recipient of the Bravo award for developing the programmer’s model for verifying real-time (‘R’) profile architecture which provides high-performing processors for safety-critical environments.
Vinu’s current research focuses on optimizing deep neural network-based systems for performance and scalability. More broadly, His research is at the intersection of systems, programming languages, and machine learning, to create a more efficient, performant, secure, privacy-preserving, and correct software.
His Ph.D. research has been mainly focused on deep neural network compression for resource-efficient inference and robustness. He is generously supported by an NVIDIA Ph.D. fellowship, mentored by Saurav Muralidharan and Michael Garland, he developed Condensa: A Programming System for Model Compression and Optimization.&lt;/p&gt;

&lt;h1 id=&#34;march-12&#34;&gt;March 12&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Daniel Bittman&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Twizzler: Evolving Operating Systems for Non-volatile Memory&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Byte addressable, non-volatile memory (NVM) demands that we rethink the entire system stack. Twizzler is an operating system designed for the near-future of NVM on the memory bus. It removes the kernel from the I/O path, provides programs with direct access to NVM, enabling simpler and more efficient long-term operations on persistent data. Twizzler provides a clean-slate programming model for persistent data, realizing the vision of Unix in a world of NVM. It does this through a pervasive notion of data identity coupled with an efficient design for persistent pointers that allows programmers to construct persistent data structures in a large, persistent, global address space. This talk will present an overview of Twizzler and discuss upcoming directions for Twizzler in security, distribution, and programming languages.Bio&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Daniel is a PhD candidate at UC Santa Cruz, advised by Ethan Miller and Peter Alvaro. His interests are in kernel programming and design, security, non-volatile memory, and concurrent programming. His current project is on developing an operating system for non-volatile memories and developing operating system designs and interfaces for better programming and data models in such an environment.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;../&#34;&gt;Archive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Languages, Systems, and Data Seminar (Fall 2020)</title>
      <link>http://lsd-ucsc.github.io/lsd-seminar/2020fa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://lsd-ucsc.github.io/lsd-seminar/2020fa/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: Fridays, noon - 1:15pm (PT)&lt;br/&gt;
&lt;strong&gt;Location&lt;/strong&gt;: The Internet &lt;br/&gt;
&lt;strong&gt;Organizers&lt;/strong&gt;: Lindsey Kuper and Tyler Sorensen &lt;br/&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The Languages, Systems, and Data Seminar meets weekly to discuss interesting topics in the areas of programming languages, systems, databases, formal methods, security, software engineering, verification, architecture, and beyond.  Our goal is to encourage interactions and discussions between students, researchers, and faculty with interests in these areas.  The seminar is open to everyone interested.  Participating students should register for the 2-credit course CSE 280O.&lt;/p&gt;

&lt;p&gt;For fall 2020, this seminar is completely virtual.  We are excited to welcome a roster of external speakers from around the world!&lt;/p&gt;

&lt;p&gt;Talks will be advertised on the &lt;a href=&#34;https://groups.google.com/g/ucsc-lsd-seminar-announce&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ucsc-lsd-seminar-announce&lt;/a&gt; (for anyone) and &lt;a href=&#34;https://groups.google.com/a/ucsc.edu/g/lsd-group/members&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;lsd-group&lt;/a&gt; (for UCSC-affiliated people) mailing lists.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Speaker&lt;/th&gt;
&lt;th&gt;Title&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#oct-2&#34;&gt;Oct. 2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;Social event and class introduction&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#oct-9&#34;&gt;Oct. 9&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://mpg.is/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Matthías Páll Gissurarson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Weakening Type Systems for Faster Prototyping&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#oct-16&#34;&gt;Oct. 16&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://wen.works/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Wen Kokke&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;An introduction to Session Types&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#oct-23&#34;&gt;Oct. 23&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://kalevalp.github.io/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Kalev Alpernas&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Correct and Secure Serverless Computing&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#oct-30&#34;&gt;Oct. 30&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://software-lab.org/people/Daniel_Lehmann.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Daniel Lehmann&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Everything Old is New Again: Binary Security of WebAssembly&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#nov-6&#34;&gt;Nov. 6&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://umazalakain.info/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Uma Zalakain&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mechanising the Linear π-Calculus&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#nov-13&#34;&gt;Nov. 13&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~kqy/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Katherine Ye&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Penrose: from mathematical notation to beautiful diagrams&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#nov-20&#34;&gt;Nov. 20&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://sites.google.com/lehigh.edu/jacobnelson/home&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Jacob Nelson&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Bundled References: An Abstraction for Highly-Concurrent Linearizable Range Queries&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#dec-4&#34;&gt;Dec. 4&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Vectorization for Digital Signal Processors via Equality Saturation&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;#dec-11&#34;&gt;Dec. 11&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.cis.upenn.edu/~euisuny/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Irene Yoon&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Modular, compositional, and executable semantics for LLVM IR&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;oct-2&#34;&gt;Oct. 2&lt;/h1&gt;

&lt;p&gt;Class introduction&lt;/p&gt;

&lt;h1 id=&#34;oct-9&#34;&gt;Oct. 9&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt;  &lt;a href=&#34;https://mpg.is/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Matthías Páll Gissurarson&lt;/a&gt; (&lt;em&gt;Chalmers University&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Weakening Type Systems for Faster Prototyping&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Types and type systems are great to provide the compiler with a partial specification of our programs, but it can often be tricky to write code that matches said specification. In this talk, I will demonstrate how we can allow developers to opt-in to a weaker type system &amp;ldquo;just get it to compile&amp;rdquo;, and what we can do to &amp;ldquo;fix&amp;rdquo; the code during compilation so that it matches the specification provided using synthesis and coercions, and hint to the developer what the issue is and how they might fix it.&lt;/p&gt;

&lt;h1 id=&#34;oct-16&#34;&gt;Oct. 16&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://wen.works/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Wen Kokke&lt;/a&gt; (&lt;em&gt;University of Edinburgh&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; An introduction to Session Types&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Much like the λ-calculus is the foundational calculus for functions, the π-calculus is the foundational calculus for message-passing concurrency. Both are terrifyingly powerful, in the sense that if you can compute something, you can do it using these languages. They&amp;rsquo;re also very scary, in the sense that you can easily write functions that &amp;ldquo;go wrong&amp;rdquo;, e.g., by getting different kinds of data mixed up, looping forever, or just getting stuck. In this talk, I&amp;rsquo;ll introduce the fundamentals of the π-calculus, and the continued effort to tame its potential for going wrong, while leaving as much of its power as possible intact. I&amp;rsquo;ll do all of this by analogy to the λ-calculus, and I&amp;rsquo;ll finish up by talk about concurrent λ-calculus—basically the answer to the question &amp;ldquo;What do I get if I smash my λs and πs together really hard?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;(The talk starts with a brief recap of the relevant bits of the untyped and simply-typed λ-calculus, just in case you could use a refresher.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Wen is a programming languages researcher at the University of Edinburgh, where she works on session types. She is also a researcher at Heriot-Watt University, where she works on lightweight verification for neural networks. In her spare time, she enjoys cooking and runs a small art space.&lt;/p&gt;

&lt;h1 id=&#34;oct-23&#34;&gt;Oct. 23&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://kalevalp.github.io/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Kalev Alpernas&lt;/a&gt; (&lt;em&gt;Tel Aviv University&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Correct and Secure Serverless Computing&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Serverless computing is a popular cloud computing paradigm that allows for easy deployment, rapid prototyping,
 and effortless, near-unlimited scalability. However, serverless computing can provide these benefits by introducing several restrictions and limitations on cloud applications, including limiting task execution time, requiring the use of ephemeral execution
 environments, and requiring that programs adopt an event-driven programming model. These limitations make it harder to write correct and secure applications.&lt;/p&gt;

&lt;p&gt;In this talk I will present two projects aimed at bridging these security and correctness gaps. The first—Trapeze—is
 a runtime IFC system that guarantees termination-sensitive non-interference,
 ensuring that sensitive data never leaks from a serverless application. The second—Watchtower—is a runtime monitoring system that checks for violation of arbitrary temporal correctness properties that cross-cut the entire application reporting to the user
 when violations occur. Watchtower also includes a record-and-replay component for locally reproducing and debugging property violations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Kalev is a 4th year PhD candidate at Tel Aviv University, under the supervision of Prof. Mooly Sagiv. His
 research interests are in the intersection of serverless computing and PL/formal methods.&lt;/p&gt;

&lt;h1 id=&#34;oct-30&#34;&gt;Oct. 30&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;http://software-lab.org/people/Daniel_Lehmann.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Daniel Lehmann&lt;/a&gt; (&lt;em&gt;University of Stuttgart&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Everything Old is New Again: Binary Security of WebAssembly&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; WebAssembly is an increasingly popular, low-level binary format designed
to run code in browsers and on other platforms safely and securely, by
strictly separating code and data, enforcing types, and limiting
indirect control flow. Still, vulnerabilities in memory-unsafe source
languages can translate to vulnerabilities in WebAssembly binaries. We
have analyzed to what extent vulnerabilities are exploitable in
WebAssembly binaries, and how this compares to native code. We find that
many classic vulnerabilities which, due to common mitigations, are no
longer exploitable in native binaries, are completely exposed in
WebAssembly. Moreover, WebAssembly enables unique attacks, such as
overwriting supposedly constant data or manipulating the heap using a
stack overflow. In this talk, we will explain several attack primitives
that allow an attacker (i) to write arbitrary memory, (ii) to overwrite
sensitive data, and (iii) to trigger unexpected behavior by diverting
control flow or manipulating the host environment. This can ultimately
lead to new forms of cross-site scripting in the browser or remote code
execution on Node.js. We will also demonstrate one of our three
end-to-end exploits, which cover three different WebAssembly platforms.
In our quantitative evaluation of real-world WebAssembly binaries, we
also measure how likely our attack primitives are feasible in practice.
Overall, our findings show a perhaps surprising lack of binary security
in WebAssembly. Finally, we will discuss some potential mitigations and
give recommendations on how to harden WebAssembly binaries in the future.&lt;/p&gt;

&lt;h1 id=&#34;nov-6&#34;&gt;Nov. 6&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://umazalakain.info/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Uma Zalakain&lt;/a&gt; (&lt;em&gt;University of Glasgow&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Mechanising the Linear π-Calculus&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; The π-calculus is a computational model for communication and concurrency. The
linear π-calculus restricts the π-calculus by demanding that every communication
channel is used exactly once. This results in more fine grained control over
communication, avoids race conditions, and is in itself enough to serve as a
target language to which the session-typed π-calculus can be compiled to.&lt;/p&gt;

&lt;p&gt;This talk will focus on mechanizing the linear π-calculus. I will first present
a mechanized syntax and an operational semantics for the untyped π-calculus. On
top of that, I will use leftover typing to define a resource-aware type system
that is parametrized by a set of usage coalgebras. I will compare this type
system with its more traditional alternative, and comment on some of its type
safety properties.&lt;/p&gt;

&lt;p&gt;Finally, I will briefly introduce some of our ongoing research, which aims to
mechanize the decidable typechecking of the linear π-calculus. We do so by
borrowing ideas from co-contextual type checking algorithms and applying them to
the linear π-calculus. This results in a constraint satisfaction problem that,
when satisfied, returns type substitutions that can be used to mechanically
build typing derivations for terms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Uma is a 2nd year PhD student at the University of Glasgow, where she works on the machine verification of typed process calculi under the supervision of Dr Ornela Dardha.
On her spare time she enjoys going out along the local riverbank for a run, and she uses every opportunity she has to hike through the Italian Alps and the Basque Pyrenees.&lt;/p&gt;

&lt;h1 id=&#34;nov-13&#34;&gt;Nov. 13&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://www.cs.cmu.edu/~kqy/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Katherine Ye&lt;/a&gt; (&lt;em&gt;Carnegie Mellon University&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Penrose: from mathematical notation to beautiful diagrams&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; How do you design a system for automatically visualizing mathematics? In this talk I will discuss the approach taken in our SIGGRAPH 2020 paper to build a tool, called Penrose, for creating mathematical diagrams.&lt;/p&gt;

&lt;p&gt;The basic functionality of Penrose is to translate abstract statements written in familiar math-like notation into one or more possible visual representations. Rather than rely on a fixed library of visualization tools, the visual representation is user-defined in a constraint-based specification language; diagrams are then generated automatically via constrained numerical optimization. The system is user-extensible to many domains of mathematics, and is fast enough for iterative design exploration. In contrast to tools that specify diagrams via direct manipulation or low-level graphics programming, Penrose enables rapid creation and exploration of diagrams that faithfully preserve the underlying mathematical meaning. We demonstrate the effectiveness and generality of the system by showing how it can be used to illustrate a diverse set of concepts from mathematics and computer graphics.&lt;/p&gt;

&lt;p&gt;For more information (and pictures!), please see our paper page:
&lt;a href=&#34;https://penrose.ink/siggraph20&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;https://penrose.ink/siggraph20&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;nov-20&#34;&gt;Nov. 20&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://sites.google.com/lehigh.edu/jacobnelson/home&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Jacob Nelson&lt;/a&gt; (&lt;em&gt;Lehigh University&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Bundled References: An Abstraction for Highly-Concurrent Linearizable Range Queries&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; As the name suggests, range queries provide the capability to return all values of a set, whose keys are contained in a given range. In a concurrent setting, this particular operation presents challenges since it can be long running. To offer linearizable range queries, we must ensure that the operations observe a consistent snapshot of the data structure even in the midst of ongoing point operations (i.e. get, put and delete). Bundled references are a new building block to provide linearizable range query operations for highly concurrent linked data structures. At its core, a bundled reference maintains the history of a given data structure link to allow range queries to traverse a path through the data structure corresponding to a particular moment in time. By traversing only links that were &amp;ldquo;alive&amp;rdquo; at the range queries outset, a range query observes a view of the data structure that is consistent with the target atomic snapshot and is made of the minimal amount of nodes that should be accessed to preserve linearizability.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; Jacob Nelson is a third-year PhD student at Lehigh University in Bethlehem, PA. His interests encompass a wide range of systems topics including highly concurrent data structures and distribution using remote direct memory access (RDMA). His most recent work is focused on how to leverage high performance one-sided RDMA operations to build a data-movement oriented transactional key-value store. Check out his &lt;a href=&#34;https://sites.google.com/lehigh.edu/jacobnelson&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;website&lt;/a&gt; for more info!&lt;/p&gt;

&lt;h1 id=&#34;dec-4&#34;&gt;Dec. 4&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt; (&lt;em&gt;Cornell University&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Vectorization for Digital Signal Processors via Equality Saturation&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Compute-heavy embedded systems, from augmented reality to 5G networking, rely on specialized hardware in the form of digital signal processors (DSPs). However, DSPs are designed to prioritize energy efficiency and predictability over programmability, with simple in-order architectures that offer little hardware-provided parallelism. Existing auto-vectorizing compilers can struggle to optimize small linear algebra kernels that rely on complex data movements. An expert can reach state-of-the-art performance by hand-writing specialized implementations to use vector instructions, but they must repeat this manual effort for each size instance. In this talk, I will describe Diospyros, a search-based compiler that automates this task of finding efficient vectorizations for smaller linear algebra kernels. Diospyros combines two automated reasoning techniques, symbolic evaluation and equality saturation over rewrite rules, to vectorize computations with irregular structure. We show that Diospyros outperforms DSP libraries by 2.8x on average and demonstrate how search-based techniques can help users reach performance competitive with expert tuning with less manual effort.&lt;/p&gt;

&lt;h1 id=&#34;dec-11&#34;&gt;Dec. 11&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href=&#34;https://www.cis.upenn.edu/~euisuny/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Irene Yoon&lt;/a&gt; (&lt;em&gt;University of Pennsylvania&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt; Modular, compositional, and executable semantics for LLVM IR&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; The LLVM framework has been a long-time favorite for compiler enthusiasts. It is both a widely used industrial-strength compiler (most recognizably, Apple’s latest macOS and iOS development tools) and a popular research tool (winning the ACM Software Systems Award in 2012).&lt;/p&gt;

&lt;p&gt;How do we best ensure that LLVM-based tools (compilers, optimizers, code instrumentation passes, etc.) do what they’re supposed to — especially for safety- or security-critical applications?&lt;/p&gt;

&lt;p&gt;This talk is an introduction to a novel formal semantics for a large, sequential subset of the LLVM IR, mechanized in the Coq proof assistant. We will see how the use of modern semantic reasoning techniques allow us to write a &lt;em&gt;compositional, modular, and executable&lt;/em&gt; semantics. In particular, I will discuss how the development of an &lt;em&gt;interaction tree&lt;/em&gt;-based semantics gives us (1) expressive combinators for defining compositional semantics, (2) a modular separation of concerns for effects in a language, and (3) a “for-free” extraction of an executable definitional interpreter.&lt;/p&gt;

&lt;p&gt;No experience with LLVM or formal verification technologies will be assumed.&lt;/p&gt;

&lt;p&gt;Source can be found on our &lt;a href=&#34;https://github.com/vellvm/vellvm&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;../&#34;&gt;Archive&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
